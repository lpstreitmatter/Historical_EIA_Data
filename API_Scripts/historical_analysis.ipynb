{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file is excluded from the repo due to its size but can be reproduced by running EIA930API_Scriptv2.py\n",
    "data = pd.read_csv(\"EIA_BAlims_2021-2023v2_full.csv\") \n",
    "\n",
    "from_var = \"fromferc\"\n",
    "to_var = \"toferc\"\n",
    "\n",
    "data = data.loc[data[from_var] != data[to_var]] # remove intra-regional transfers\n",
    "# Process the reported data so that fromferc = exporter and toferc = importer\n",
    "data_exp = data.loc[data[\"value\"] >= 0].copy()\n",
    "data_exp[\"Reporter\"] = data_exp[from_var]\n",
    "data_imp = data.loc[data[\"value\"] <= 0].copy()\n",
    "data_imp[\"Reporter\"] = data_imp[from_var]\n",
    "data_imp.rename(columns={from_var:to_var,to_var:from_var},inplace=True)\n",
    "data_imp[\"value\"] *= -1\n",
    "\n",
    "df = pd.concat([data_imp, data_exp], axis=0)\n",
    "df[\"Combined\"] = df[[from_var, to_var]].apply(tuple, 1).apply(sorted).apply(tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot flow duration curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interfaces = list(set(df[\"Combined\"]))\n",
    "percentile = 0.999 # change as desired to control for outlier data (an ESIG report used 99th percentile)\n",
    "\n",
    "for (one,two) in interfaces:\n",
    "    forward = df.loc[(df[from_var] == one) & (df[to_var] == two)]\n",
    "    reverse = df.loc[(df[from_var] == two) & (df[to_var] == one)]\n",
    "    try:\n",
    "        forward_lim = forward.groupby([from_var, to_var])[\"value\"].quantile(percentile, interpolation=\"lower\").values[0]\n",
    "    except:\n",
    "        forward_lim = 1000000\n",
    "    try:\n",
    "        reverse_lim = reverse.groupby([from_var, to_var])[\"value\"].quantile(percentile, interpolation=\"lower\").values[0]\n",
    "    except:\n",
    "        reverse_lim = 1000000\n",
    "    forward = forward[forward[\"value\"]<forward_lim] # remove outliers above each interface's forward percentile\n",
    "    reverse = reverse[reverse[\"value\"]<reverse_lim] # remove outliers above each interface's reverse percentile\n",
    "    ax = plt.axes()\n",
    "    ax.plot(forward[forward[\"Reporter\"]==one][\"value\"].sort_values(ascending=False).reset_index(drop=True), label=f\"Forward (Reported by {one})\",color=\"red\")\n",
    "    ax.plot(forward[forward[\"Reporter\"]==two][\"value\"].sort_values(ascending=False).reset_index(drop=True), label=f\"Forward (Reported by {two})\",color=\"blue\")\n",
    "    ax.plot((reverse[reverse[\"Reporter\"]==one][\"value\"].sort_values(ascending=False)*-1).reset_index(drop=True), label=f\"Reverse (Reported by {one})\",color=\"red\",linestyle=\"dashed\")\n",
    "    ax.plot((reverse[reverse[\"Reporter\"]==two][\"value\"].sort_values(ascending=False)*-1).reset_index(drop=True), label=f\"Reverse (Reported by {two})\",color=\"blue\",linestyle=\"dashed\")\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.set_title(f\"{one}-{two} Historical Flows (2021-2023)\")\n",
    "    ax.set_ylabel(\"MW Transfer\")\n",
    "    ax.set_xlabel(\"Number of Hours\")\n",
    "    ax.legend()\n",
    "    plt.savefig(f\"{one}-{two}_HistoricalDurationCurve.png\")\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Maxes to produce csv of historical interface limits\n",
    "\n",
    "Note the different methods for determining the \"maxmimum\" interface flow according to outlier removal and reporting entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = 0.99 # change as desired to control for outlier data (an ESIG report used 99th percentile)\n",
    "df_max = df.groupby([\"fromferc\", \"toferc\",\"Reporter\"])[\"value\"].max().to_frame(\"Max\")\n",
    "df_max_avg = df_max.groupby([\"fromferc\", \"toferc\"])[\"Max\"].mean().to_frame(\"Max_Avg\") # finds average of the max flows reported by both regions\n",
    "df_max_max = df_max.groupby([\"fromferc\", \"toferc\"])[\"Max\"].max().to_frame(\"Max_Max\") # takes the max of the max flows reported by both regions\n",
    "\n",
    "df_99 = df.groupby([\"fromferc\", \"toferc\",\"Reporter\"])[\"value\"].quantile(percentile, interpolation=\"lower\").to_frame(f\"Q{percentile}\")\n",
    "df_99_avg = df_99.groupby([\"fromferc\", \"toferc\"])[f\"Q{percentile}\"].mean().to_frame(f\"Q{percentile}_Avg\") # finds average of the 99th % flows reported by both regions\n",
    "df_99_max = df_99.groupby([\"fromferc\", \"toferc\"])[f\"Q{percentile}\"].max().to_frame(f\"Q{percentile}_Max\") # takes the max of the 99th % flows reported by both regions\n",
    "\n",
    "df_hist = pd.concat([df_max_avg,df_max_max,df_99_avg,df_99_max], axis=1)#.reset_index()\n",
    "#df_hist.to_csv(\"historicals_2021-2023.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
